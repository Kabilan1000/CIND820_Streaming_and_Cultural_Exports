{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f81b3e-ab2e-4f22-8aad-45158cf8e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider files: {'Netflix': PosixPath('data/netflix_titles.csv'), 'Amazon Prime': PosixPath('data/amazon_prime_titles.csv'), 'Disney+': PosixPath('data/disney_plus_titles.csv')}\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "import io\n",
    "import time\n",
    "\n",
    "#Data directory\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "PROVIDER_FILES = {\n",
    "    \"Netflix\": DATA_DIR / \"netflix_titles.csv\",\n",
    "    \"Amazon Prime\": DATA_DIR / \"amazon_prime_titles.csv\",\n",
    "    \"Disney+\": DATA_DIR / \"disney_plus_titles.csv\",\n",
    "}\n",
    "for k, v in PROVIDER_FILES.items():\n",
    "    if not v.exists():\n",
    "        raise FileNotFoundError(f\"Missing file for {k}: {v}\")\n",
    "print(\"Provider files:\", PROVIDER_FILES)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c28d424-fffd-4aef-a531-21538f235334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_any_df(path: Path) -> pd.DataFrame:\n",
    "    ext = path.suffix.lower()\n",
    "    if ext == \".csv\":\n",
    "        return pd.read_csv(path)\n",
    "    #JSON: try standard then JSON-lines\n",
    "    try:\n",
    "        return pd.read_json(path, lines=False)\n",
    "    except ValueError:\n",
    "        return pd.read_json(path, lines=True)\n",
    "\n",
    "def to_snake(name: str) -> str:\n",
    "    name = re.sub(r\"[^\\w]+\", \"_\", name.strip())\n",
    "    name = re.sub(r\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", name)\n",
    "    return name.lower().strip(\"_\")\n",
    "\n",
    "def get_col(df: pd.DataFrame, aliases: List[str]) -> Optional[str]:\n",
    "    #Try snake-case alias match\n",
    "    snake = {to_snake(c): c for c in df.columns}\n",
    "    for a in aliases:\n",
    "        if a in snake:\n",
    "            return snake[a]\n",
    "    #Fallback: case-insensitive plain match\n",
    "    lowers = [al.replace(\"_\", \" \") for al in aliases]\n",
    "    for c in df.columns:\n",
    "        if c.lower() in lowers:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "STANDARD_COLS = {\n",
    "    \"title\": [\"title\", \"show_title\", \"name\"],\n",
    "    \"type\": [\"type\", \"content_type\", \"show_type\"],\n",
    "    \"release_year\": [\"release_year\", \"year\"],\n",
    "    \"genres\": [\"genres\", \"genre\", \"listed_in\"],\n",
    "    \"imdb_rating\": [\"imdb_rating\", \"imdb_score\", \"score\"],\n",
    "    \"imdb_votes\": [\"imdb_votes\", \"votes\"],\n",
    "    \"content_rating\": [\"rating\", \"age_certification\", \"maturity_rating\"],\n",
    "}\n",
    "\n",
    "\n",
    "def coerce_schema(df: pd.DataFrame, platform: str) -> pd.DataFrame:\n",
    "    out = pd.DataFrame()\n",
    "    for std, aliases in STANDARD_COLS.items():\n",
    "        aliases_snake = [to_snake(a) for a in aliases]\n",
    "        if std not in aliases_snake:\n",
    "            aliases_snake.append(std)\n",
    "        col = get_col(df, aliases_snake)\n",
    "        out[std] = df[col] if col is not None else np.nan\n",
    "    out[\"platform\"] = platform    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efcc6051-3bde-4f99-aacc-88f7b517e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized shapes:\n",
      "Netflix -> (8807, 8)\n",
      "Amazon Prime -> (9668, 8)\n",
      "Disney+ -> (1450, 8)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for plat, path in PROVIDER_FILES.items():\n",
    "    raw = load_any_df(path)\n",
    "    std = coerce_schema(raw, plat)\n",
    "    dfs.append(std)\n",
    "\n",
    "print(\"Standardized shapes:\")\n",
    "for d in dfs:\n",
    "    print(f\"{d['platform'].iloc[0]} -> {d.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "410879dd-880d-43aa-a5ab-7cb185c45da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-clean dtypes:\n",
      "[                      title     type  release_year  \\\n",
      "0      Dick Johnson Is Dead    Movie          2020   \n",
      "1             Blood & Water  TV Show          2021   \n",
      "2                 Ganglands  TV Show          2021   \n",
      "3     Jailbirds New Orleans  TV Show          2021   \n",
      "4              Kota Factory  TV Show          2021   \n",
      "...                     ...      ...           ...   \n",
      "8802                 Zodiac    Movie          2007   \n",
      "8803            Zombie Dumb  TV Show          2018   \n",
      "8804             Zombieland    Movie          2009   \n",
      "8805                   Zoom    Movie          2006   \n",
      "8806                 Zubaan    Movie          2015   \n",
      "\n",
      "                                                 genres  imdb_rating  \\\n",
      "0                                       [Documentaries]          NaN   \n",
      "1     [International TV Shows, TV Dramas, TV Mysteries]          NaN   \n",
      "2     [Crime TV Shows, International TV Shows, TV Ac...          NaN   \n",
      "3                              [Docuseries, Reality TV]          NaN   \n",
      "4     [International TV Shows, Romantic TV Shows, TV...          NaN   \n",
      "...                                                 ...          ...   \n",
      "8802                   [Cult Movies, Dramas, Thrillers]          NaN   \n",
      "8803           [Kids' TV, Korean TV Shows, TV Comedies]          NaN   \n",
      "8804                          [Comedies, Horror Movies]          NaN   \n",
      "8805               [Children & Family Movies, Comedies]          NaN   \n",
      "8806   [Dramas, International Movies, Music & Musicals]          NaN   \n",
      "\n",
      "      imdb_votes content_rating platform  \n",
      "0            NaN          PG-13  Netflix  \n",
      "1            NaN          TV-MA  Netflix  \n",
      "2            NaN          TV-MA  Netflix  \n",
      "3            NaN          TV-MA  Netflix  \n",
      "4            NaN          TV-MA  Netflix  \n",
      "...          ...            ...      ...  \n",
      "8802         NaN              R  Netflix  \n",
      "8803         NaN          TV-Y7  Netflix  \n",
      "8804         NaN              R  Netflix  \n",
      "8805         NaN             PG  Netflix  \n",
      "8806         NaN          TV-14  Netflix  \n",
      "\n",
      "[8807 rows x 8 columns],                         title     type  release_year  \\\n",
      "0         The Grand Seduction    Movie          2014   \n",
      "1        Take Care Good Night    Movie          2018   \n",
      "2        Secrets of Deception    Movie          2017   \n",
      "3          Pink: Staying True    Movie          2014   \n",
      "4               Monster Maker    Movie          1989   \n",
      "...                       ...      ...           ...   \n",
      "9663      Pride Of The Bowery    Movie          1940   \n",
      "9664            Planet Patrol  TV Show          2018   \n",
      "9665                  Outpost    Movie          2008   \n",
      "9666  Maradona: Blessed Dream  TV Show          2021   \n",
      "9667              Harry Brown    Movie          2010   \n",
      "\n",
      "                         genres  imdb_rating  imdb_votes content_rating  \\\n",
      "0               [Comedy, Drama]          NaN         NaN            NaN   \n",
      "1        [Drama, International]          NaN         NaN            13+   \n",
      "2     [Action, Drama, Suspense]          NaN         NaN            NaN   \n",
      "3                 [Documentary]          NaN         NaN            NaN   \n",
      "4              [Drama, Fantasy]          NaN         NaN            NaN   \n",
      "...                         ...          ...         ...            ...   \n",
      "9663                   [Comedy]          NaN         NaN             7+   \n",
      "9664                 [TV Shows]          NaN         NaN            13+   \n",
      "9665                   [Action]          NaN         NaN              R   \n",
      "9666            [Drama, Sports]          NaN         NaN          TV-MA   \n",
      "9667  [Action, Drama, Suspense]          NaN         NaN              R   \n",
      "\n",
      "          platform  \n",
      "0     Amazon Prime  \n",
      "1     Amazon Prime  \n",
      "2     Amazon Prime  \n",
      "3     Amazon Prime  \n",
      "4     Amazon Prime  \n",
      "...            ...  \n",
      "9663  Amazon Prime  \n",
      "9664  Amazon Prime  \n",
      "9665  Amazon Prime  \n",
      "9666  Amazon Prime  \n",
      "9667  Amazon Prime  \n",
      "\n",
      "[9668 rows x 8 columns],                                                  title     type  release_year  \\\n",
      "0     Duck the Halls: A Mickey Mouse Christmas Special    Movie          2016   \n",
      "1                               Ernest Saves Christmas    Movie          1988   \n",
      "2                         Ice Age: A Mammoth Christmas    Movie          2011   \n",
      "3                           The Queen Family Singalong    Movie          2021   \n",
      "4                                The Beatles: Get Back  TV Show          2021   \n",
      "...                                                ...      ...           ...   \n",
      "1445                          X-Men Origins: Wolverine    Movie          2009   \n",
      "1446    Night at the Museum: Battle of the Smithsonian    Movie          2009   \n",
      "1447                                   Eddie the Eagle    Movie          2016   \n",
      "1448                              Bend It Like Beckham    Movie          2003   \n",
      "1449             Captain Sparky vs. The Flying Saucers    Movie          2012   \n",
      "\n",
      "                                               genres  imdb_rating  \\\n",
      "0                                 [Animation, Family]          NaN   \n",
      "1                                            [Comedy]          NaN   \n",
      "2                         [Animation, Comedy, Family]          NaN   \n",
      "3                                           [Musical]          NaN   \n",
      "4                     [Docuseries, Historical, Music]          NaN   \n",
      "...                                               ...          ...   \n",
      "1445      [Action-Adventure, Family, Science Fiction]          NaN   \n",
      "1446               [Action-Adventure, Comedy, Family]          NaN   \n",
      "1447                    [Biographical, Comedy, Drama]          NaN   \n",
      "1448                   [Buddy, Comedy, Coming of Age]          NaN   \n",
      "1449  [Action-Adventure, Animals & Nature, Animation]          NaN   \n",
      "\n",
      "      imdb_votes content_rating platform  \n",
      "0            NaN           TV-G  Disney+  \n",
      "1            NaN             PG  Disney+  \n",
      "2            NaN           TV-G  Disney+  \n",
      "3            NaN          TV-PG  Disney+  \n",
      "4            NaN            NaN  Disney+  \n",
      "...          ...            ...      ...  \n",
      "1445         NaN          PG-13  Disney+  \n",
      "1446         NaN             PG  Disney+  \n",
      "1447         NaN          PG-13  Disney+  \n",
      "1448         NaN          PG-13  Disney+  \n",
      "1449         NaN           TV-G  Disney+  \n",
      "\n",
      "[1450 rows x 8 columns]]\n"
     ]
    }
   ],
   "source": [
    "def normalize_strings(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str).str.strip()\n",
    "            df.loc[df[c].isin([\"nan\", \"NaN\", \"None\"]), c] = np.nan\n",
    "    return df\n",
    "\n",
    "def to_numeric(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def safe_split(x, seps=(\",\", \"|\", \";\")):\n",
    "    if pd.isna(x): return []\n",
    "    if isinstance(x, list): return [str(i).strip() for i in x if str(i).strip()]\n",
    "    s = str(x)\n",
    "    for sep in seps:\n",
    "        s = s.replace(sep, \",\")\n",
    "    return [i.strip() for i in s.split(\",\") if i.strip()]\n",
    "\n",
    "def split_multivalue_cols(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].apply(safe_split)\n",
    "    return df\n",
    "\n",
    "cleaned = []\n",
    "for df in dfs:\n",
    "    df = df.copy()\n",
    "    df = normalize_strings(df, [\"title\",\"type\",\"country\",\"genres\",\"director\",\"cast\",\"date_added\",\"duration\"])\n",
    "    df = to_numeric(df, [\"release_year\",\"imdb_rating\",\"imdb_votes\"])\n",
    "    df = split_multivalue_cols(df, [\"country\",\"genres\",\"cast\",\"director\"])\n",
    "\n",
    "    #Ensure genres is a list,default only if  missing\n",
    "    if \"genres\" in df.columns:\n",
    "        df[\"genres\"] = df[\"genres\"].apply(lambda g: g if isinstance(g, list) and len(g) else [\"Unknown\"])\n",
    "\n",
    "    cleaned.append(df)\n",
    "\n",
    "print(\"Post-clean dtypes:\")\n",
    "cleaned[0].dtypes.head(12)\n",
    "print (cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f9919e-5afa-4c9a-84af-b73f4233e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_median(s: pd.Series):\n",
    "    s2 = s.dropna()\n",
    "    return s2.median() if not s2.empty else np.nan\n",
    "\n",
    "def impute_values_safely(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "#Fill numerical values with medians if it exists\n",
    "    for c in [\"imdb_rating\", \"imdb_votes\", \"release_year\"]:\n",
    "        if c in df.columns:\n",
    "            med = _safe_median(df[c])\n",
    "            if not np.isnan(med):\n",
    "                df[c] = df[c].fillna(med)\n",
    "\n",
    "#List categoricals ensuring non-empty lists\n",
    "    def ensure_list(val):\n",
    "        if isinstance(val, list):\n",
    "            return val if len(val) else [\"Unknown\"]\n",
    "        if pd.isna(val):\n",
    "            return [\"Unknown\"]\n",
    "        return [str(val)]\n",
    "\n",
    "    for c in [\"country\",\"genres\",\"cast\",\"director\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].apply(ensure_list)\n",
    "\n",
    "#Fill Scalar strings only when missing\n",
    "    for c in [\"title\",\"type\",\"date_added\",\"duration\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].where(df[c].notna(), \"Unknown\")\n",
    "\n",
    "    return df\n",
    "\n",
    "imputed = [impute_values_safely(df) for df in cleaned]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b16af9a-25d6-40fd-9420-e56ea1f69972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De-duplicated: 8807 → 8802 (removed 5)\n",
      "De-duplicated: 9668 → 9659 (removed 9)\n",
      "De-duplicated: 1450 → 1450 (removed 0)\n"
     ]
    }
   ],
   "source": [
    "def _normalize_title_for_dupes(s: pd.Series) -> pd.Series:\n",
    "    def norm(x: str) -> str:\n",
    "        if pd.isna(x): return x\n",
    "        x = str(x).strip().lower()\n",
    "        x = re.sub(r\"\\s+\", \" \", x)\n",
    "        x = re.sub(r\"[^\\w\\s]\", \"\", x)\n",
    "        return x\n",
    "    return s.astype(str).apply(norm)\n",
    "\n",
    "def drop_dupes_robust(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"__norm_title__\"] = _normalize_title_for_dupes(df[\"title\"]) if \"title\" in df.columns else np.nan\n",
    "    keys = [\"__norm_title__\"]\n",
    "    for k in [\"platform\",\"type\",\"release_year\"]:\n",
    "        if k in df.columns:\n",
    "            keys.append(k)\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=keys).reset_index(drop=True)\n",
    "    after = len(df)\n",
    "    print(f\"De-duplicated: {before} → {after} (removed {before - after})\")\n",
    "    return df.drop(columns=[\"__norm_title__\"])\n",
    "\n",
    "deduped = [drop_dupes_robust(df) for df in imputed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8983ea28-741c-4f66-a992-6b181fe9e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb directory: data/imdb\n",
      "Found: ['title.akas.tsv.gz', 'title.basics.tsv.gz', 'title.ratings.tsv.gz']\n"
     ]
    }
   ],
   "source": [
    "#Grab IMDB data\n",
    "IMDB_DIR = DATA_DIR / \"imdb\"\n",
    "IMDB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"IMDb directory:\", IMDB_DIR)\n",
    "print(\"Found:\", sorted(p.name for p in IMDB_DIR.glob(\"*.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f58cd0-48d5-4310-8320-420a5ae16688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#TAke only whats needed\n",
    "\n",
    "use_basics  = [\"tconst\",\"titleType\",\"primaryTitle\",\"originalTitle\",\"startYear\"]\n",
    "use_ratings = [\"tconst\",\"averageRating\",\"numVotes\"]\n",
    "\n",
    "basics  = pd.read_csv(IMDB_DIR/\"title.basics.tsv.gz\",  sep=\"\\t\",\n",
    "                      usecols=use_basics,  na_values=\"\\\\N\", low_memory=False)\n",
    "ratings = pd.read_csv(IMDB_DIR/\"title.ratings.tsv.gz\", sep=\"\\t\",\n",
    "                      usecols=use_ratings, na_values=\"\\\\N\", low_memory=False)\n",
    "\n",
    "#Keep only movies & series that have ratings\n",
    "basics = basics[basics[\"titleType\"].isin([\"movie\",\"tvSeries\",\"tvMiniSeries\"])].copy()\n",
    "imdb   = basics.merge(ratings, on=\"tconst\", how=\"inner\")\n",
    "\n",
    "#dtypes\n",
    "imdb[\"startYear\"]     = pd.to_numeric(imdb[\"startYear\"], errors=\"coerce\").astype(\"Int64\")\n",
    "imdb[\"averageRating\"] = pd.to_numeric(imdb[\"averageRating\"], errors=\"coerce\")\n",
    "imdb[\"numVotes\"]      = pd.to_numeric(imdb[\"numVotes\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bfab5f9-42eb-4199-aec1-082565552f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Normalize titles and map types\n",
    "\n",
    "def norm_title_series(s: pd.Series) -> pd.Series:\n",
    "    def _n(x):\n",
    "        if pd.isna(x): return None\n",
    "        x = str(x).strip().lower()\n",
    "        x = re.sub(r\"\\(aka[^)]*\\)|\\[[^\\]]*\\]|\\([^)]*\\)\", \"\", x)  \n",
    "        x = re.sub(r\"[^\\w\\s]\", \"\", x)                           \n",
    "        x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "        x = re.sub(r\"^(the|a|an)\\s+\", \"\", x)                    \n",
    "        return x\n",
    "    return s.apply(_n)\n",
    "\n",
    "#left: merged dataset\n",
    "combined_df = pd.concat(deduped, ignore_index=True)\n",
    "left = combined_df.copy()\n",
    "left[\"__norm_title\"] = norm_title_series(left[\"title\"])\n",
    "left[\"__type_grp\"] = (left[\"type\"].astype(str).str.strip().str.lower().map(lambda t: \"Movie\" if t == \"movie\" else \"TV\"))\n",
    "\n",
    "#right: IMDb\n",
    "imdb[\"__norm_title_p\"] = norm_title_series(imdb[\"primaryTitle\"])\n",
    "imdb[\"__norm_title_o\"] = norm_title_series(imdb[\"originalTitle\"])\n",
    "imdb[\"__type_grp\"]     = imdb[\"titleType\"].map(lambda t: \"Movie\" if t==\"movie\" else \"TV\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc395974-bdba-43f9-ad08-7caa9d735e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming titles that successfully matched an IMDb record: 50.0%\n"
     ]
    }
   ],
   "source": [
    "#Start joining\n",
    "cand = imdb[imdb[\"startYear\"].notna()].copy()\n",
    "\n",
    "cols = [\"tconst\",\"titleType\",\"__type_grp\",\"startYear\",\"averageRating\",\"numVotes\"]\n",
    "\n",
    "cand1 = cand[cols + [\"__norm_title_p\"]].rename(columns={\"__norm_title_p\":\"__norm_title\"})\n",
    "cand2 = cand[cols + [\"__norm_title_o\"]].rename(columns={\"__norm_title_o\":\"__norm_title\"})\n",
    "\n",
    "cand_all = (\n",
    "    pd.concat([cand1, cand2], ignore_index=True)\n",
    "      .dropna(subset=[\"__norm_title\"])\n",
    "      .drop_duplicates(subset=[\"tconst\",\"__norm_title\",\"startYear\",\"__type_grp\"])\n",
    ")\n",
    "_type_rank = {\"tvSeries\": 0, \"tvMiniSeries\": 1, \"movie\": 0}\n",
    "cand_all[\"__type_rank\"] = cand_all[\"titleType\"].map(_type_rank).fillna(2)\n",
    "\n",
    "cand_all = (\n",
    "    cand_all.sort_values(\n",
    "        [\"__norm_title\",\"startYear\",\"__type_grp\",\"__type_rank\",\"numVotes\",\"averageRating\"],\n",
    "        ascending=[True, True, True, True, False, False]\n",
    "    )\n",
    "    .drop_duplicates(subset=[\"__norm_title\",\"startYear\",\"__type_grp\"], keep=\"first\")\n",
    ")\n",
    "assert not cand_all.duplicated(subset=[\"__norm_title\",\"startYear\",\"__type_grp\"]).any()\n",
    "#speed filtering\n",
    "_needed_years = set(left[\"release_year\"].dropna().astype(int))\n",
    "_needed_years = _needed_years | {y + 1 for y in _needed_years} | {y - 1 for y in _needed_years}\n",
    "cand_all = cand_all[cand_all[\"startYear\"].isin(_needed_years)]\n",
    "cand_all = cand_all[cand_all[\"numVotes\"].fillna(0) >= 50] \n",
    "\n",
    "#Minor categorical optimization\n",
    "cand_all[\"__type_grp\"] = cand_all[\"__type_grp\"].astype(\"category\")\n",
    "left[\"__type_grp\"] = left[\"__type_grp\"].astype(\"category\")\n",
    "m1 = left.merge(\n",
    "    cand_all,\n",
    "    left_on=[\"__norm_title\",\"release_year\",\"__type_grp\"],\n",
    "    right_on=[\"__norm_title\",\"startYear\",\"__type_grp\"],\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "print(f\"Streaming titles that successfully matched an IMDb record: {m1['averageRating'].notna().mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b25b321-a99b-4d4b-8072-83549f165a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass-2: starting ±1 year backfill...\n",
      "Coverage pass-2 (±1): 58.7%\n",
      "Pass-2 done in 0.6s\n"
     ]
    }
   ],
   "source": [
    "#PAss 2 with 1 year bakcfill\n",
    "t2_start = time.perf_counter()\n",
    "print(\"Pass-2: starting ±1 year backfill...\")\n",
    "\n",
    "need_mask = m1[\"averageRating\"].isna()\n",
    "\n",
    "#Rows still missing\n",
    "need = m1.loc[need_mask, [\"__norm_title\", \"__type_grp\", \"release_year\"]].copy()\n",
    "\n",
    "#+1 year candidates\n",
    "j1 = need.assign(release_year_shift=need[\"release_year\"] + 1).merge(\n",
    "    cand_all,\n",
    "    left_on=[\"__norm_title\", \"__type_grp\", \"release_year_shift\"],\n",
    "    right_on=[\"__norm_title\", \"__type_grp\", \"startYear\"],\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\",\n",
    "    suffixes=(\"\", \"_r\"),\n",
    ")\n",
    "\n",
    "#-1 year candidates\n",
    "j2 = need.assign(release_year_shift=need[\"release_year\"] - 1).merge(\n",
    "    cand_all,\n",
    "    left_on=[\"__norm_title\", \"__type_grp\", \"release_year_shift\"],\n",
    "    right_on=[\"__norm_title\", \"__type_grp\", \"startYear\"],\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\",\n",
    "    suffixes=(\"\", \"_r\"),\n",
    ")\n",
    "\n",
    "#Pick best: prefer j1 when present else j2\n",
    "r_fill = j1[\"averageRating\"].combine_first(j2[\"averageRating\"])\n",
    "v_fill = j1[\"numVotes\"].combine_first(j2[\"numVotes\"])\n",
    "t_fill = j1[\"tconst\"].combine_first(j2[\"tconst\"])\n",
    "\n",
    "m2 = m1.copy()\n",
    "m2.loc[need_mask, \"averageRating\"] = r_fill.values\n",
    "m2.loc[need_mask, \"numVotes\"]      = v_fill.values\n",
    "m2.loc[need_mask, \"tconst\"]        = t_fill.values\n",
    "\n",
    "print(f\"Coverage pass-2 (±1): {m2['averageRating'].notna().mean()*100:.1f}%\")\n",
    "print(f\"Pass-2 done in {time.perf_counter() - t2_start:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "147155b3-8376-4048-b6a9-bd2ef38d19a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass-3: starting AKAs backfill...\n",
      "Coverage pass-3 (AKAs, same year): 65.3%\n",
      "Pass-3 done in 175.8s\n"
     ]
    }
   ],
   "source": [
    "#Pass-3: AKAs same-year backfill\n",
    "t3_start = time.perf_counter()\n",
    "print(\"Pass-3: starting AKAs backfill...\")\n",
    "\n",
    "use_akas = [\"titleId\", \"title\", \"region\", \"isOriginalTitle\"]\n",
    "akas = pd.read_csv(IMDB_DIR / \"title.akas.tsv.gz\", sep=\"\\t\", usecols=use_akas, na_values=\"\\\\N\", low_memory=False)\n",
    "\n",
    "akas[\"__norm_title\"] = norm_title_series(akas[\"title\"])\n",
    "aka_join = (\n",
    "    akas.dropna(subset=[\"__norm_title\"])\n",
    "        .merge(\n",
    "            imdb[[\"tconst\", \"__type_grp\", \"startYear\", \"averageRating\", \"numVotes\"]],\n",
    "            left_on=\"titleId\",\n",
    "            right_on=\"tconst\",\n",
    "            how=\"inner\",\n",
    "        )[[\"__norm_title\", \"__type_grp\", \"startYear\", \"averageRating\", \"numVotes\", \"tconst\"]]\n",
    "        .sort_values(\n",
    "            [\"__norm_title\", \"__type_grp\", \"startYear\", \"numVotes\", \"averageRating\"],\n",
    "            ascending=[True, True, True, False, False]\n",
    "        )\n",
    "        .drop_duplicates(subset=[\"__norm_title\", \"__type_grp\", \"startYear\"], keep=\"first\")\n",
    ")\n",
    "_needed_years = set(m2[\"release_year\"].dropna().astype(int))\n",
    "aka_join = aka_join[aka_join[\"startYear\"].isin(_needed_years)]\n",
    "\n",
    "\n",
    "need_mask = m2[\"averageRating\"].isna() & m2[\"__norm_title\"].notna()\n",
    "need = m2.loc[need_mask, [\"__norm_title\", \"__type_grp\", \"release_year\"]]\n",
    "\n",
    "j_aka = need.merge(\n",
    "    aka_join,\n",
    "    left_on=[\"__norm_title\", \"__type_grp\", \"release_year\"],\n",
    "    right_on=[\"__norm_title\", \"__type_grp\", \"startYear\"],\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\",\n",
    ")\n",
    "\n",
    "m3 = m2.copy()\n",
    "m3.loc[need_mask, \"averageRating\"] = j_aka[\"averageRating\"].values\n",
    "m3.loc[need_mask, \"numVotes\"]      = j_aka[\"numVotes\"].values\n",
    "m3.loc[need_mask, \"tconst\"]        = j_aka[\"tconst\"].values\n",
    "\n",
    "print(f\"Coverage pass-3 (AKAs, same year): {m3['averageRating'].notna().mean()*100:.1f}%\")\n",
    "print(f\"Pass-3 done in {time.perf_counter() - t3_start:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2ae15f4-1243-44ff-94f5-7d2c02a0200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries: building country_map from AKAs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4785/1096519609.py:66: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby([\"titleId\",\"region\"]).size().reset_index(name=\"n\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_map sizes — p1: 0 p2: 12123 p3: 12523 final: 12415\n",
      "m3 country non-null: 12856\n",
      "Countries added \n",
      "Countries step done in 5.6s\n"
     ]
    }
   ],
   "source": [
    "#Use unicode add in coutnry lists\n",
    "import unicodedata\n",
    "t_ctry_start = time.perf_counter()\n",
    "print(\"Countries: building country_map from AKAs...\")\n",
    "\n",
    "need_cols = {\"titleId\",\"title\",\"region\",\"isOriginalTitle\"}\n",
    "if not need_cols.issubset(akas.columns):\n",
    "    use_akas = [\"titleId\", \"title\", \"region\", \"isOriginalTitle\"]\n",
    "    akas = pd.read_csv(IMDB_DIR / \"title.akas.tsv.gz\", sep=\"\\t\",\n",
    "                       usecols=use_akas, na_values=\"\\\\N\", low_memory=False)\n",
    "    \n",
    "_needed_tconsts = set()\n",
    "if \"m3\" in globals() and \"tconst\" in m3.columns:\n",
    "    try:\n",
    "        _needed_tconsts |= set(m3.loc[m3[\"country\"].isna(), \"tconst\"].dropna().astype(str))\n",
    "    except Exception:\n",
    "        _needed_tconsts |= set(m3[\"tconst\"].dropna().astype(str))\n",
    "elif \"m2\" in globals() and \"tconst\" in m2.columns:\n",
    "    _needed_tconsts |= set(m2[\"tconst\"].dropna().astype(str))\n",
    "if _needed_tconsts:\n",
    "    akas = akas[akas[\"titleId\"].isin(_needed_tconsts)]\n",
    "\n",
    "akas = akas[akas[\"region\"].notna()]\n",
    "akas = akas[akas[\"region\"].str.len().between(2, 3)]\n",
    "akas[\"region\"] = akas[\"region\"].str.upper().astype(\"category\")\n",
    "\n",
    "\n",
    "#Normalizer\n",
    "def _norm(s: str) -> str:\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"\\(aka[^)]*\\)|\\[[^\\]]*\\]|\\([^)]*\\)\", \" \", s)\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    s = re.sub(r\"^(the|a|an)\\s+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "#Strict original-title region\n",
    "a = akas[[\"titleId\",\"title\",\"region\",\"isOriginalTitle\"]].copy()\n",
    "a[\"isOriginalTitle\"] = a[\"isOriginalTitle\"].astype(str).isin([\"1\",\"True\",\"true\"])\n",
    "p1 = (\n",
    "    a.loc[a[\"isOriginalTitle\"] & a[\"region\"].notna(), [\"titleId\",\"region\"]]\n",
    "     .drop_duplicates(subset=[\"titleId\"])\n",
    "     .rename(columns={\"titleId\":\"tconst\",\"region\":\"country\"})\n",
    ")\n",
    "\n",
    "#Region of AKA whose title == basics.originalTitle (normalized)\n",
    "b = imdb[[\"tconst\",\"originalTitle\"]].copy()\n",
    "b[\"original_norm\"] = b[\"originalTitle\"].astype(str).map(_norm)\n",
    "ak = akas[[\"titleId\",\"title\",\"region\"]].copy()\n",
    "ak[\"title_norm\"] = ak[\"title\"].astype(str).map(_norm)\n",
    "\n",
    "p2 = (\n",
    "    b.merge(ak, left_on=[\"tconst\",\"original_norm\"], right_on=[\"titleId\",\"title_norm\"], how=\"left\")\n",
    "     .dropna(subset=[\"region\"])\n",
    "     .sort_values([\"tconst\"])  \n",
    "     .drop_duplicates(subset=[\"tconst\"])\n",
    "     .rename(columns={\"region\":\"country\"})\n",
    "     [[\"tconst\",\"country\"]]\n",
    ")\n",
    "\n",
    "#Modal region\n",
    "modal = (\n",
    "    akas.loc[akas[\"region\"].notna(), [\"titleId\",\"region\"]]\n",
    "        .groupby([\"titleId\",\"region\"]).size().reset_index(name=\"n\")\n",
    "        .sort_values([\"titleId\",\"n\"], ascending=[True, False])\n",
    "        .groupby(\"titleId\", as_index=False).first()[[\"titleId\",\"region\"]]\n",
    "        .rename(columns={\"titleId\":\"tconst\",\"region\":\"country\"})\n",
    ")\n",
    "\n",
    "#Combine priorities: P1 > P2 > P3\n",
    "country_map = modal.set_index(\"tconst\")\n",
    "# overlay P2 then P1\n",
    "country_map.update(p2.set_index(\"tconst\"))\n",
    "country_map.update(p1.set_index(\"tconst\"))\n",
    "country_map = country_map.reset_index()\n",
    "\n",
    "#Clean\n",
    "country_map[\"country\"] = country_map[\"country\"].astype(str).str.upper().str.strip()\n",
    "country_map = country_map[country_map[\"country\"].str.len() == 2].drop_duplicates(\"tconst\")\n",
    "\n",
    "print(\"country_map sizes — p1:\", len(p1), \"p2:\", len(p2), \"p3:\", len(modal), \"final:\", len(country_map))\n",
    "\n",
    "#Optimize merge types for speed/memory\n",
    "country_map[\"country\"] = country_map[\"country\"].astype(\"category\")\n",
    "\n",
    "#Merge into the frames\n",
    "m3 = m3.merge(country_map, on=\"tconst\", how=\"left\")\n",
    "if \"df\" in globals() and \"tconst\" in df.columns:\n",
    "    df = df.merge(country_map, on=\"tconst\", how=\"left\")\n",
    "if \"combined_df\" in globals() and \"tconst\" in combined_df.columns:\n",
    "    combined_df = combined_df.merge(country_map, on=\"tconst\", how=\"left\")\n",
    "if \"out\" in globals() and \"tconst\" in out.columns:\n",
    "    out = out.merge(country_map, on=\"tconst\", how=\"left\")\n",
    "\n",
    "#Quick counters\n",
    "def _nn(frame, name):\n",
    "    try:\n",
    "        print(f\"{name} country non-null:\", int(frame['country'].notna().sum()))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "_nn(m3, \"m3\")\n",
    "if \"df\" in globals(): _nn(df, \"df\")\n",
    "if \"combined_df\" in globals(): _nn(combined_df, \"combined_df\")\n",
    "if \"out\" in globals(): _nn(out, \"out\")\n",
    "\n",
    "print(\"Countries added \")\n",
    "print(f\"Countries step done in {time.perf_counter() - t_ctry_start:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a40dc493-b830-40df-99e9-b7eb07b69939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (19911, 8)\n",
      "\n",
      "Counts by platform:\n",
      "platform\n",
      "Amazon Prime    9659\n",
      "Netflix         8802\n",
      "Disney+         1450\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Counts by type:\n",
      "type\n",
      "Movie      14984\n",
      "TV Show     4927\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top missingness (%):\n",
      "imdb_votes        100.0\n",
      "imdb_rating       100.0\n",
      "content_rating      1.7\n",
      "title               0.0\n",
      "genres              0.0\n",
      "release_year        0.0\n",
      "type                0.0\n",
      "platform            0.0\n",
      "dtype: float64\n",
      "\n",
      "Remaining duplicates by robust key: 0\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat(deduped, ignore_index=True)\n",
    "\n",
    "print(\"Combined shape:\", combined_df.shape)\n",
    "print(\"\\nCounts by platform:\")\n",
    "print(combined_df[\"platform\"].value_counts(dropna=False))\n",
    "\n",
    "if \"type\" in combined_df.columns:\n",
    "    print(\"\\nCounts by type:\")\n",
    "    print(combined_df[\"type\"].value_counts(dropna=False))\n",
    "\n",
    "missing = (combined_df.isna().mean().sort_values(ascending=False) * 100).round(1)\n",
    "print(\"\\nTop missingness (%):\")\n",
    "print(missing.head(12))\n",
    "\n",
    "tmp = combined_df.copy()\n",
    "tmp[\"__norm_title__\"] = _normalize_title_for_dupes(tmp[\"title\"])\n",
    "keys = [k for k in [\"__norm_title__\",\"platform\",\"type\",\"release_year\"] if k in tmp.columns]\n",
    "dups = tmp.duplicated(subset=keys).sum()\n",
    "print(\"\\nRemaining duplicates by robust key:\", dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d00ec6f-39c6-4dc8-9ec5-16ef5a9a63a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered incomplete rows: 19911 -> 12855 (removed 7056)\n",
      "Clean dataset saved: (12855, 15)\n"
     ]
    }
   ],
   "source": [
    "out = m3.rename(columns={\"averageRating\": \"imdb_rating\", \"numVotes\": \"imdb_votes\"})\n",
    "if out.columns.duplicated().any():\n",
    "    out = out.loc[:, ~out.columns.duplicated(keep=\"last\")]\n",
    "    \n",
    "#Make genres readable in CSV\n",
    "if \"genres\" in out.columns:\n",
    "    out[\"genres\"] = out[\"genres\"].apply(lambda xs: \" | \".join(xs) if isinstance(xs, list) else (xs if isinstance(xs, str) else \"\"))\n",
    "\n",
    "#Cast IMDb fields\n",
    "for c in (\"imdb_rating\", \"imdb_votes\"):\n",
    "    if c in out.columns:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "\n",
    "def _is_missing(s: pd.Series) -> pd.Series:\n",
    "    return s.isna() | s.astype(str).str.fullmatch(r\"\\s*|unknown|none|nan\", case=False)\n",
    "\n",
    "_out = out.copy()\n",
    "\n",
    "#Keep only valid country codes (2–3 letters)\n",
    "if \"country\" in _out.columns:\n",
    "    _out = _out[_out[\"country\"].notna()]\n",
    "    _out = _out[_out[\"country\"].astype(str).str.fullmatch(r\"[A-Z]{2,3}\")]\n",
    "\n",
    "req = [\"title\", \"type\", \"platform\", \"genres\"]\n",
    "for c in req:\n",
    "    if c in _out.columns:\n",
    "        _out = _out[~_is_missing(_out[c])]\n",
    "\n",
    "#Year must be present and plausible\n",
    "if \"release_year\" in _out.columns:\n",
    "    _out = _out[_out[\"release_year\"].between(1900, 2100, inclusive=\"both\")]\n",
    "\n",
    "print(f\"Filtered incomplete rows: {len(out)} -> {len(_out)} (removed {len(out)-len(_out)})\")\n",
    "out = _out\n",
    "\n",
    "cols = [\n",
    "    \"title\", \"type\", \"release_year\", \"genres\", \"platform\", \"content_rating\",\n",
    "    \"imdb_rating\", \"imdb_votes\", \"country\", \"tconst\"\n",
    "]\n",
    "\n",
    "cols = [c for c in cols if c in out.columns]\n",
    "out[cols].to_csv(\"clean_streaming_metadata.csv\", index=False)\n",
    "\n",
    "print(\"Clean dataset saved:\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cf60606-cd82-4b88-aaaa-61c2a315f18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 12855\n",
      "Columns: ['title', 'type', 'release_year', 'genres', 'platform', 'content_rating', 'imdb_rating', 'imdb_votes', 'country', 'tconst']\n",
      "\n",
      "Release Year Stats:\n",
      "count    12855.000000\n",
      "mean      2009.938934\n",
      "std         16.667641\n",
      "min       1920.000000\n",
      "25%       2009.000000\n",
      "50%       2016.000000\n",
      "75%       2019.000000\n",
      "max       2021.000000\n",
      "Name: release_year, dtype: float64\n",
      "\n",
      "IMDb Rating Stats:\n",
      "count    12855.000000\n",
      "mean         6.223003\n",
      "std          1.254114\n",
      "min          1.000000\n",
      "25%          5.500000\n",
      "50%          6.400000\n",
      "75%          7.100000\n",
      "max          9.600000\n",
      "Name: imdb_rating, dtype: float64\n",
      "\n",
      "Type distribution:\n",
      "type\n",
      "Movie      78.016336\n",
      "TV Show    21.983664\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values (%):\n",
      "title             0.000000\n",
      "type              0.000000\n",
      "release_year      0.000000\n",
      "genres            0.000000\n",
      "platform          0.000000\n",
      "content_rating    1.190198\n",
      "imdb_rating       0.000000\n",
      "imdb_votes        0.000000\n",
      "country           0.000000\n",
      "tconst            0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Stats\n",
    "df = pd.read_csv(\"clean_streaming_metadata.csv\")\n",
    "\n",
    "#General overview\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "#Release year\n",
    "print(\"\\nRelease Year Stats:\")\n",
    "print(df['release_year'].describe())\n",
    "\n",
    "#IMDb rating\n",
    "print(\"\\nIMDb Rating Stats:\")\n",
    "print(df['imdb_rating'].describe())\n",
    "\n",
    "#Content type ratio\n",
    "print(\"\\nType distribution:\")\n",
    "print(df['type'].value_counts(normalize=True) * 100)\n",
    "\n",
    "#Missing value percentages\n",
    "print(\"\\nMissing values (%):\")\n",
    "print(df.isnull().mean() * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11d692e1-4002-4af8-9238-30f426fae345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>platform</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>country</th>\n",
       "      <th>tconst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dick Johnson Is Dead</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2020</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7560.0</td>\n",
       "      <td>AU</td>\n",
       "      <td>tt11394180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blood &amp; Water</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>2021</td>\n",
       "      <td>International TV Shows | TV Dramas | TV Mysteries</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>FR</td>\n",
       "      <td>tt9839146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ganglands</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>2021</td>\n",
       "      <td>Crime TV Shows | International TV Shows | TV A...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4934.0</td>\n",
       "      <td>FR</td>\n",
       "      <td>tt13278100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jailbirds New Orleans</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>2021</td>\n",
       "      <td>Docuseries | Reality TV</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>6.5</td>\n",
       "      <td>338.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>tt15320436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Midnight Mass</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV Dramas | TV Horror | TV Mysteries</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>7.7</td>\n",
       "      <td>163639.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>tt10574558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My Little Pony: A New Generation</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2021</td>\n",
       "      <td>Children &amp; Family Movies</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>PG</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4977.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>tt10101702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sankofa</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1993</td>\n",
       "      <td>Dramas | Independent Movies | International Mo...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>7.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>US</td>\n",
       "      <td>tt0108041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Starling</td>\n",
       "      <td>Movie</td>\n",
       "      <td>2021</td>\n",
       "      <td>Comedies | Dramas</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.4</td>\n",
       "      <td>16631.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>tt5164438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vendetta: Truth, Lies and The Mafia</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>2021</td>\n",
       "      <td>Crime TV Shows | Docuseries | International TV...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>6.7</td>\n",
       "      <td>373.0</td>\n",
       "      <td>IT</td>\n",
       "      <td>tt14216574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bangkok Breaking</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>2021</td>\n",
       "      <td>Crime TV Shows | International TV Shows | TV A...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>5.9</td>\n",
       "      <td>461.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>tt14202282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title     type  release_year  \\\n",
       "0                 Dick Johnson Is Dead    Movie          2020   \n",
       "1                        Blood & Water  TV Show          2021   \n",
       "2                            Ganglands  TV Show          2021   \n",
       "3                Jailbirds New Orleans  TV Show          2021   \n",
       "4                        Midnight Mass  TV Show          2021   \n",
       "5     My Little Pony: A New Generation    Movie          2021   \n",
       "6                              Sankofa    Movie          1993   \n",
       "7                         The Starling    Movie          2021   \n",
       "8  Vendetta: Truth, Lies and The Mafia  TV Show          2021   \n",
       "9                     Bangkok Breaking  TV Show          2021   \n",
       "\n",
       "                                              genres platform content_rating  \\\n",
       "0                                      Documentaries  Netflix          PG-13   \n",
       "1  International TV Shows | TV Dramas | TV Mysteries  Netflix          TV-MA   \n",
       "2  Crime TV Shows | International TV Shows | TV A...  Netflix          TV-MA   \n",
       "3                            Docuseries | Reality TV  Netflix          TV-MA   \n",
       "4               TV Dramas | TV Horror | TV Mysteries  Netflix          TV-MA   \n",
       "5                           Children & Family Movies  Netflix             PG   \n",
       "6  Dramas | Independent Movies | International Mo...  Netflix          TV-MA   \n",
       "7                                  Comedies | Dramas  Netflix          PG-13   \n",
       "8  Crime TV Shows | Docuseries | International TV...  Netflix          TV-MA   \n",
       "9  Crime TV Shows | International TV Shows | TV A...  Netflix          TV-MA   \n",
       "\n",
       "   imdb_rating  imdb_votes country      tconst  \n",
       "0          7.4      7560.0      AU  tt11394180  \n",
       "1          6.7      4705.0      FR   tt9839146  \n",
       "2          7.2      4934.0      FR  tt13278100  \n",
       "3          6.5       338.0      IN  tt15320436  \n",
       "4          7.7    163639.0      IN  tt10574558  \n",
       "5          6.8      4977.0      GB  tt10101702  \n",
       "6          7.0       884.0      US   tt0108041  \n",
       "7          6.4     16631.0      IN   tt5164438  \n",
       "8          6.7       373.0      IT  tt14216574  \n",
       "9          5.9       461.0      GB  tt14202282  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c1664-459e-4a22-92ba-774728644365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
