{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f81b3e-ab2e-4f22-8aad-45158cf8e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/netflix-shows ...\n",
      "Extracted to data/netflix\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/amazon-prime-movies-and-tv-shows ...\n",
      "Extracted to data/amazon_prime\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/disney-movies-and-tv-shows ...\n",
      "Extracted to data/disney+\n",
      "Netflix -> data/netflix/netflix_titles.csv\n",
      "Amazon Prime -> data/amazon_prime/amazon_prime_titles.csv\n",
      "Disney+ -> data/disney+/disney_plus_titles.csv\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "import io\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "#Data directory\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "#Kaggle dataset URLs\n",
    "URLS = {\n",
    "    \"Netflix\": \"https://www.kaggle.com/api/v1/datasets/download/shivamb/netflix-shows\",\n",
    "    \"Amazon Prime\": \"https://www.kaggle.com/api/v1/datasets/download/shivamb/amazon-prime-movies-and-tv-shows\",\n",
    "    \"Disney+\": \"https://www.kaggle.com/api/v1/datasets/download/shivamb/disney-movies-and-tv-shows\"\n",
    "}\n",
    "\n",
    "def download_and_extract(url, dest_folder):\n",
    "    print(f\"Downloading from {url} ...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to download {url} – Kaggle may require authentication.\")\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        z.extractall(dest_folder)\n",
    "    print(f\"Extracted to {dest_folder}\")\n",
    "\n",
    "for name, url in URLS.items():\n",
    "    folder = DATA_DIR / name.replace(\" \", \"_\").lower()\n",
    "    folder.mkdir(exist_ok=True)\n",
    "    download_and_extract(url, folder)\n",
    "\n",
    "#Set up CSVs\n",
    "FILES = {\n",
    "    \"Netflix\": next((DATA_DIR / \"netflix\").rglob(\"*.csv\")),\n",
    "    \"Amazon Prime\": next((DATA_DIR / \"amazon_prime\").rglob(\"*.csv\")),\n",
    "    \"Disney+\": next((DATA_DIR / \"disney+\").rglob(\"*.csv\")),\n",
    "}\n",
    "\n",
    "for k, v in FILES.items():\n",
    "    print(k, \"->\", v)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c28d424-fffd-4aef-a531-21538f235334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_any_df(path: Path) -> pd.DataFrame:\n",
    "    ext = path.suffix.lower()\n",
    "    if ext == \".csv\":\n",
    "        return pd.read_csv(path)\n",
    "    # JSON: try standard then JSON-lines\n",
    "    try:\n",
    "        return pd.read_json(path, lines=False)\n",
    "    except ValueError:\n",
    "        return pd.read_json(path, lines=True)\n",
    "\n",
    "def to_snake(name: str) -> str:\n",
    "    name = re.sub(r\"[^\\w]+\", \"_\", name.strip())\n",
    "    name = re.sub(r\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", name)\n",
    "    return name.lower().strip(\"_\")\n",
    "\n",
    "def get_col(df: pd.DataFrame, aliases: List[str]) -> Optional[str]:\n",
    "    # Try snake-case alias match\n",
    "    snake = {to_snake(c): c for c in df.columns}\n",
    "    for a in aliases:\n",
    "        if a in snake:\n",
    "            return snake[a]\n",
    "    # Fallback: case-insensitive plain match\n",
    "    lowers = [al.replace(\"_\", \" \") for al in aliases]\n",
    "    for c in df.columns:\n",
    "        if c.lower() in lowers:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "STANDARD_COLS = {\n",
    "    \"title\": [\"title\", \"show_title\", \"name\"],\n",
    "    \"type\": [\"type\", \"content_type\", \"show_type\"],\n",
    "    \"release_year\": [\"release_year\", \"year\"],\n",
    "    \"genres\": [\"genres\", \"genre\", \"listed_in\"],\n",
    "    \"imdb_rating\": [\"imdb_rating\", \"imdb_score\", \"score\"],\n",
    "    \"imdb_votes\": [\"imdb_votes\", \"votes\"],\n",
    "    \"content_rating\": [\"rating\", \"age_certification\", \"maturity_rating\"],\n",
    "}\n",
    "\n",
    "\n",
    "def coerce_schema(df: pd.DataFrame, platform: str) -> pd.DataFrame:\n",
    "    out = pd.DataFrame()\n",
    "    for std, aliases in STANDARD_COLS.items():\n",
    "        aliases_snake = [to_snake(a) for a in aliases]\n",
    "        if std not in aliases_snake:\n",
    "            aliases_snake.append(std)\n",
    "        col = get_col(df, aliases_snake)\n",
    "        out[std] = df[col] if col is not None else np.nan\n",
    "    out[\"platform\"] = platform    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcc6051-3bde-4f99-aacc-88f7b517e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized shapes:\n",
      "Netflix -> (8807, 8)\n",
      "Amazon Prime -> (9668, 8)\n",
      "Disney+ -> (1450, 8)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for plat, path in FILES.items():\n",
    "    raw = load_any_df(path)\n",
    "    std = coerce_schema(raw, plat)\n",
    "    dfs.append(std)\n",
    "\n",
    "print(\"Standardized shapes:\")\n",
    "for d in dfs:\n",
    "    print(f\"{d['platform'].iloc[0]} -> {d.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410879dd-880d-43aa-a5ab-7cb185c45da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-clean dtypes:\n",
      "[                      title     type  release_year  \\\n",
      "0      Dick Johnson Is Dead    Movie          2020   \n",
      "1             Blood & Water  TV Show          2021   \n",
      "2                 Ganglands  TV Show          2021   \n",
      "3     Jailbirds New Orleans  TV Show          2021   \n",
      "4              Kota Factory  TV Show          2021   \n",
      "...                     ...      ...           ...   \n",
      "8802                 Zodiac    Movie          2007   \n",
      "8803            Zombie Dumb  TV Show          2018   \n",
      "8804             Zombieland    Movie          2009   \n",
      "8805                   Zoom    Movie          2006   \n",
      "8806                 Zubaan    Movie          2015   \n",
      "\n",
      "                                                 genres  imdb_rating  \\\n",
      "0                                       [Documentaries]          NaN   \n",
      "1     [International TV Shows, TV Dramas, TV Mysteries]          NaN   \n",
      "2     [Crime TV Shows, International TV Shows, TV Ac...          NaN   \n",
      "3                              [Docuseries, Reality TV]          NaN   \n",
      "4     [International TV Shows, Romantic TV Shows, TV...          NaN   \n",
      "...                                                 ...          ...   \n",
      "8802                   [Cult Movies, Dramas, Thrillers]          NaN   \n",
      "8803           [Kids' TV, Korean TV Shows, TV Comedies]          NaN   \n",
      "8804                          [Comedies, Horror Movies]          NaN   \n",
      "8805               [Children & Family Movies, Comedies]          NaN   \n",
      "8806   [Dramas, International Movies, Music & Musicals]          NaN   \n",
      "\n",
      "      imdb_votes content_rating platform  \n",
      "0            NaN          PG-13  Netflix  \n",
      "1            NaN          TV-MA  Netflix  \n",
      "2            NaN          TV-MA  Netflix  \n",
      "3            NaN          TV-MA  Netflix  \n",
      "4            NaN          TV-MA  Netflix  \n",
      "...          ...            ...      ...  \n",
      "8802         NaN              R  Netflix  \n",
      "8803         NaN          TV-Y7  Netflix  \n",
      "8804         NaN              R  Netflix  \n",
      "8805         NaN             PG  Netflix  \n",
      "8806         NaN          TV-14  Netflix  \n",
      "\n",
      "[8807 rows x 8 columns],                         title     type  release_year  \\\n",
      "0         The Grand Seduction    Movie          2014   \n",
      "1        Take Care Good Night    Movie          2018   \n",
      "2        Secrets of Deception    Movie          2017   \n",
      "3          Pink: Staying True    Movie          2014   \n",
      "4               Monster Maker    Movie          1989   \n",
      "...                       ...      ...           ...   \n",
      "9663      Pride Of The Bowery    Movie          1940   \n",
      "9664            Planet Patrol  TV Show          2018   \n",
      "9665                  Outpost    Movie          2008   \n",
      "9666  Maradona: Blessed Dream  TV Show          2021   \n",
      "9667              Harry Brown    Movie          2010   \n",
      "\n",
      "                         genres  imdb_rating  imdb_votes content_rating  \\\n",
      "0               [Comedy, Drama]          NaN         NaN            NaN   \n",
      "1        [Drama, International]          NaN         NaN            13+   \n",
      "2     [Action, Drama, Suspense]          NaN         NaN            NaN   \n",
      "3                 [Documentary]          NaN         NaN            NaN   \n",
      "4              [Drama, Fantasy]          NaN         NaN            NaN   \n",
      "...                         ...          ...         ...            ...   \n",
      "9663                   [Comedy]          NaN         NaN             7+   \n",
      "9664                 [TV Shows]          NaN         NaN            13+   \n",
      "9665                   [Action]          NaN         NaN              R   \n",
      "9666            [Drama, Sports]          NaN         NaN          TV-MA   \n",
      "9667  [Action, Drama, Suspense]          NaN         NaN              R   \n",
      "\n",
      "          platform  \n",
      "0     Amazon Prime  \n",
      "1     Amazon Prime  \n",
      "2     Amazon Prime  \n",
      "3     Amazon Prime  \n",
      "4     Amazon Prime  \n",
      "...            ...  \n",
      "9663  Amazon Prime  \n",
      "9664  Amazon Prime  \n",
      "9665  Amazon Prime  \n",
      "9666  Amazon Prime  \n",
      "9667  Amazon Prime  \n",
      "\n",
      "[9668 rows x 8 columns],                                                  title     type  release_year  \\\n",
      "0     Duck the Halls: A Mickey Mouse Christmas Special    Movie          2016   \n",
      "1                               Ernest Saves Christmas    Movie          1988   \n",
      "2                         Ice Age: A Mammoth Christmas    Movie          2011   \n",
      "3                           The Queen Family Singalong    Movie          2021   \n",
      "4                                The Beatles: Get Back  TV Show          2021   \n",
      "...                                                ...      ...           ...   \n",
      "1445                          X-Men Origins: Wolverine    Movie          2009   \n",
      "1446    Night at the Museum: Battle of the Smithsonian    Movie          2009   \n",
      "1447                                   Eddie the Eagle    Movie          2016   \n",
      "1448                              Bend It Like Beckham    Movie          2003   \n",
      "1449             Captain Sparky vs. The Flying Saucers    Movie          2012   \n",
      "\n",
      "                                               genres  imdb_rating  \\\n",
      "0                                 [Animation, Family]          NaN   \n",
      "1                                            [Comedy]          NaN   \n",
      "2                         [Animation, Comedy, Family]          NaN   \n",
      "3                                           [Musical]          NaN   \n",
      "4                     [Docuseries, Historical, Music]          NaN   \n",
      "...                                               ...          ...   \n",
      "1445      [Action-Adventure, Family, Science Fiction]          NaN   \n",
      "1446               [Action-Adventure, Comedy, Family]          NaN   \n",
      "1447                    [Biographical, Comedy, Drama]          NaN   \n",
      "1448                   [Buddy, Comedy, Coming of Age]          NaN   \n",
      "1449  [Action-Adventure, Animals & Nature, Animation]          NaN   \n",
      "\n",
      "      imdb_votes content_rating platform  \n",
      "0            NaN           TV-G  Disney+  \n",
      "1            NaN             PG  Disney+  \n",
      "2            NaN           TV-G  Disney+  \n",
      "3            NaN          TV-PG  Disney+  \n",
      "4            NaN            NaN  Disney+  \n",
      "...          ...            ...      ...  \n",
      "1445         NaN          PG-13  Disney+  \n",
      "1446         NaN             PG  Disney+  \n",
      "1447         NaN          PG-13  Disney+  \n",
      "1448         NaN          PG-13  Disney+  \n",
      "1449         NaN           TV-G  Disney+  \n",
      "\n",
      "[1450 rows x 8 columns]]\n"
     ]
    }
   ],
   "source": [
    "def normalize_strings(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str).str.strip()\n",
    "            df.loc[df[c].isin([\"nan\", \"NaN\", \"None\"]), c] = np.nan\n",
    "    return df\n",
    "\n",
    "def to_numeric(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def safe_split(x, seps=(\",\", \"|\", \";\")):\n",
    "    if pd.isna(x): return []\n",
    "    if isinstance(x, list): return [str(i).strip() for i in x if str(i).strip()]\n",
    "    s = str(x)\n",
    "    for sep in seps:\n",
    "        s = s.replace(sep, \",\")\n",
    "    return [i.strip() for i in s.split(\",\") if i.strip()]\n",
    "\n",
    "def split_multivalue_cols(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].apply(safe_split)\n",
    "    return df\n",
    "\n",
    "cleaned = []\n",
    "for df in dfs:\n",
    "    df = df.copy()\n",
    "    df = normalize_strings(df, [\"title\",\"type\",\"country\",\"genres\",\"director\",\"cast\",\"date_added\",\"duration\"])\n",
    "    df = to_numeric(df, [\"release_year\",\"imdb_rating\",\"imdb_votes\"])\n",
    "    df = split_multivalue_cols(df, [\"country\",\"genres\",\"cast\",\"director\"])\n",
    "\n",
    "    #Ensure genres is a list,default only if  missing\n",
    "    if \"genres\" in df.columns:\n",
    "        df[\"genres\"] = df[\"genres\"].apply(lambda g: g if isinstance(g, list) and len(g) else [\"Unknown\"])\n",
    "\n",
    "    cleaned.append(df)\n",
    "\n",
    "print(\"Post-clean dtypes:\")\n",
    "cleaned[0].dtypes.head(12)\n",
    "print (cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f9919e-5afa-4c9a-84af-b73f4233e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_median(s: pd.Series):\n",
    "    s2 = s.dropna()\n",
    "    return s2.median() if not s2.empty else np.nan\n",
    "\n",
    "def impute_values_safely(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "# Fill numerical values with medians if it exists\n",
    "    for c in [\"imdb_rating\", \"imdb_votes\", \"release_year\"]:\n",
    "        if c in df.columns:\n",
    "            med = _safe_median(df[c])\n",
    "            if not np.isnan(med):\n",
    "                df[c] = df[c].fillna(med)\n",
    "\n",
    "# List categoricals ensuring non-empty lists\n",
    "    def ensure_list(val):\n",
    "        if isinstance(val, list):\n",
    "            return val if len(val) else [\"Unknown\"]\n",
    "        if pd.isna(val):\n",
    "            return [\"Unknown\"]\n",
    "        return [str(val)]\n",
    "\n",
    "    for c in [\"country\",\"genres\",\"cast\",\"director\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].apply(ensure_list)\n",
    "\n",
    "# Fill Scalar strings only when missing\n",
    "    for c in [\"title\",\"type\",\"date_added\",\"duration\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].where(df[c].notna(), \"Unknown\")\n",
    "\n",
    "    return df\n",
    "\n",
    "imputed = [impute_values_safely(df) for df in cleaned]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b16af9a-25d6-40fd-9420-e56ea1f69972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De-duplicated: 8807 → 8802 (removed 5)\n",
      "De-duplicated: 9668 → 9659 (removed 9)\n",
      "De-duplicated: 1450 → 1450 (removed 0)\n"
     ]
    }
   ],
   "source": [
    "def _normalize_title_for_dupes(s: pd.Series) -> pd.Series:\n",
    "    def norm(x: str) -> str:\n",
    "        if pd.isna(x): return x\n",
    "        x = str(x).strip().lower()\n",
    "        x = re.sub(r\"\\s+\", \" \", x)\n",
    "        x = re.sub(r\"[^\\w\\s]\", \"\", x)\n",
    "        return x\n",
    "    return s.astype(str).apply(norm)\n",
    "\n",
    "def drop_dupes_robust(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"__norm_title__\"] = _normalize_title_for_dupes(df[\"title\"]) if \"title\" in df.columns else np.nan\n",
    "    keys = [\"__norm_title__\"]\n",
    "    for k in [\"platform\",\"type\",\"release_year\"]:\n",
    "        if k in df.columns:\n",
    "            keys.append(k)\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=keys).reset_index(drop=True)\n",
    "    after = len(df)\n",
    "    print(f\"De-duplicated: {before} → {after} (removed {before - after})\")\n",
    "    return df.drop(columns=[\"__norm_title__\"])\n",
    "\n",
    "deduped = [drop_dupes_robust(df) for df in imputed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8983ea28-741c-4f66-a992-6b181fe9e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Exists: data/imdb/title.basics.tsv.gz\n",
      "✓ Exists: data/imdb/title.ratings.tsv.gz\n",
      "✓ Exists: data/imdb/title.akas.tsv.gz\n",
      "IMDb files in: [PosixPath('data/imdb/title.ratings.tsv.gz'), PosixPath('data/imdb/Disney+.tsv.gz'), PosixPath('data/imdb/title.akas.tsv.gz'), PosixPath('data/imdb/basics.tsv.gz'), PosixPath('data/imdb/title.basics.tsv.gz')]\n"
     ]
    }
   ],
   "source": [
    "#Grab IMDB data\n",
    "import urllib.request\n",
    "\n",
    "IMDB_DIR = DATA_DIR / \"imdb\"\n",
    "IMDB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMDB_URLS = {\n",
    "    \"title.basics.tsv.gz\":  \"https://datasets.imdbws.com/title.basics.tsv.gz\",\n",
    "    \"title.ratings.tsv.gz\": \"https://datasets.imdbws.com/title.ratings.tsv.gz\",\n",
    "    \"title.akas.tsv.gz\":    \"https://datasets.imdbws.com/title.akas.tsv.gz\",  # optional\n",
    "}\n",
    "\n",
    "for fname, url in IMDB_URLS.items():\n",
    "    out = IMDB_DIR / fname\n",
    "    if out.exists() and out.stat().st_size > 0:\n",
    "        print(f\"✓ Exists: {out}\")\n",
    "        continue\n",
    "    print(f\"Downloading {fname} …\")\n",
    "    urllib.request.urlretrieve(url, out)\n",
    "print(\"IMDb files in:\", list(IMDB_DIR.glob(\"*.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f58cd0-48d5-4310-8320-420a5ae16688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#TAke only whats needed\n",
    "\n",
    "use_basics  = [\"tconst\",\"titleType\",\"primaryTitle\",\"originalTitle\",\"startYear\"]\n",
    "use_ratings = [\"tconst\",\"averageRating\",\"numVotes\"]\n",
    "\n",
    "basics  = pd.read_csv(IMDB_DIR/\"title.basics.tsv.gz\",  sep=\"\\t\",\n",
    "                      usecols=use_basics,  na_values=\"\\\\N\", low_memory=False)\n",
    "ratings = pd.read_csv(IMDB_DIR/\"title.ratings.tsv.gz\", sep=\"\\t\",\n",
    "                      usecols=use_ratings, na_values=\"\\\\N\", low_memory=False)\n",
    "\n",
    "#Keep only movies & series that have ratings\n",
    "basics = basics[basics[\"titleType\"].isin([\"movie\",\"tvSeries\",\"tvMiniSeries\"])].copy()\n",
    "imdb   = basics.merge(ratings, on=\"tconst\", how=\"inner\")\n",
    "\n",
    "#dtypes\n",
    "imdb[\"startYear\"]     = pd.to_numeric(imdb[\"startYear\"], errors=\"coerce\").astype(\"Int64\")\n",
    "imdb[\"averageRating\"] = pd.to_numeric(imdb[\"averageRating\"], errors=\"coerce\")\n",
    "imdb[\"numVotes\"]      = pd.to_numeric(imdb[\"numVotes\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bfab5f9-42eb-4199-aec1-082565552f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Normalize titles and map types\n",
    "\n",
    "def norm_title_series(s: pd.Series) -> pd.Series:\n",
    "    def _n(x):\n",
    "        if pd.isna(x): return None\n",
    "        x = str(x).strip().lower()\n",
    "        x = re.sub(r\"\\(aka[^)]*\\)|\\[[^\\]]*\\]|\\([^)]*\\)\", \"\", x)  # drop aka/brackets\n",
    "        x = re.sub(r\"[^\\w\\s]\", \"\", x)                           # remove punct\n",
    "        x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "        x = re.sub(r\"^(the|a|an)\\s+\", \"\", x)                    # drop leading articles\n",
    "        return x\n",
    "    return s.apply(_n)\n",
    "\n",
    "# left: your merged dataset\n",
    "combined_df = pd.concat(deduped, ignore_index=True)  # if not already run\n",
    "left = combined_df.copy()\n",
    "left[\"__norm_title\"] = norm_title_series(left[\"title\"])\n",
    "left[\"__type_grp\"] = (left[\"type\"].astype(str).str.strip().str.lower().map(lambda t: \"Movie\" if t == \"movie\" else \"TV\"))\n",
    "\n",
    "# right: IMDb\n",
    "imdb[\"__norm_title_p\"] = norm_title_series(imdb[\"primaryTitle\"])\n",
    "imdb[\"__norm_title_o\"] = norm_title_series(imdb[\"originalTitle\"])\n",
    "imdb[\"__type_grp\"]     = imdb[\"titleType\"].map(lambda t: \"Movie\" if t==\"movie\" else \"TV\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc395974-bdba-43f9-ad08-7caa9d735e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming titles that successfully matched an IMDb record: 53.7%\n"
     ]
    }
   ],
   "source": [
    "#Start joining\n",
    "cand = imdb[imdb[\"startYear\"].notna()].copy()\n",
    "\n",
    "cols = [\"tconst\",\"titleType\",\"__type_grp\",\"startYear\",\"averageRating\",\"numVotes\"]\n",
    "\n",
    "cand1 = cand[cols + [\"__norm_title_p\"]].rename(columns={\"__norm_title_p\":\"__norm_title\"})\n",
    "cand2 = cand[cols + [\"__norm_title_o\"]].rename(columns={\"__norm_title_o\":\"__norm_title\"})\n",
    "\n",
    "cand_all = (\n",
    "    pd.concat([cand1, cand2], ignore_index=True)\n",
    "      .dropna(subset=[\"__norm_title\"])\n",
    "      .drop_duplicates(subset=[\"tconst\",\"__norm_title\",\"startYear\",\"__type_grp\"])\n",
    ")\n",
    "_type_rank = {\"tvSeries\": 0, \"tvMiniSeries\": 1, \"movie\": 0}\n",
    "cand_all[\"__type_rank\"] = cand_all[\"titleType\"].map(_type_rank).fillna(2)\n",
    "\n",
    "cand_all = (\n",
    "    cand_all.sort_values(\n",
    "        [\"__norm_title\",\"startYear\",\"__type_grp\",\"__type_rank\",\"numVotes\",\"averageRating\"],\n",
    "        ascending=[True, True, True, True, False, False]\n",
    "    )\n",
    "    .drop_duplicates(subset=[\"__norm_title\",\"startYear\",\"__type_grp\"], keep=\"first\")\n",
    ")\n",
    "assert not cand_all.duplicated(subset=[\"__norm_title\",\"startYear\",\"__type_grp\"]).any()\n",
    "\n",
    "m1 = left.merge(\n",
    "    cand_all,\n",
    "    left_on=[\"__norm_title\",\"release_year\",\"__type_grp\"],\n",
    "    right_on=[\"__norm_title\",\"startYear\",\"__type_grp\"],\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "print(f\"Streaming titles that successfully matched an IMDb record: {m1['averageRating'].notna().mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b25b321-a99b-4d4b-8072-83549f165a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass-2 (±1): 62.9%\n"
     ]
    }
   ],
   "source": [
    "#PAss 2 with 1 year bakcfill\n",
    "need_mask = m1[\"averageRating\"].isna()\n",
    "\n",
    "#Rows still missing\n",
    "need = m1.loc[need_mask, [\"__norm_title\", \"__type_grp\", \"release_year\"]].copy()\n",
    "\n",
    "#+1 year candidates\n",
    "j1 = need.assign(release_year_shift=need[\"release_year\"] + 1).merge(\n",
    "    cand_all,\n",
    "    left_on=[\"__norm_title\", \"__type_grp\", \"release_year_shift\"],\n",
    "    right_on=[\"__norm_title\", \"__type_grp\", \"startYear\"],\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\",\n",
    "    suffixes=(\"\", \"_r\"),\n",
    ")\n",
    "\n",
    "#-1 year candidates\n",
    "j2 = need.assign(release_year_shift=need[\"release_year\"] - 1).merge(\n",
    "    cand_all,\n",
    "    left_on=[\"__norm_title\", \"__type_grp\", \"release_year_shift\"],\n",
    "    right_on=[\"__norm_title\", \"__type_grp\", \"startYear\"],\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\",\n",
    "    suffixes=(\"\", \"_r\"),\n",
    ")\n",
    "\n",
    "#Pick best: prefer j1 when present else j2\n",
    "r_fill = j1[\"averageRating\"].combine_first(j2[\"averageRating\"])\n",
    "v_fill = j1[\"numVotes\"].combine_first(j2[\"numVotes\"])\n",
    "t_fill = j1[\"tconst\"].combine_first(j2[\"tconst\"])\n",
    "\n",
    "m2 = m1.copy()\n",
    "m2.loc[need_mask, \"averageRating\"] = r_fill.values\n",
    "m2.loc[need_mask, \"numVotes\"]      = v_fill.values\n",
    "m2.loc[need_mask, \"tconst\"]        = t_fill.values\n",
    "\n",
    "print(f\"Pass-2 (±1): {m2['averageRating'].notna().mean()*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147155b3-8376-4048-b6a9-bd2ef38d19a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass-3 (AKAs, same year): 66.0%\n"
     ]
    }
   ],
   "source": [
    "# Pass-3: AKAs same-year backfill\n",
    "use_akas = [\"titleId\", \"title\"]\n",
    "akas = pd.read_csv(IMDB_DIR / \"title.akas.tsv.gz\", sep=\"\\t\", usecols=use_akas, na_values=\"\\\\N\", low_memory=False)\n",
    "\n",
    "akas[\"__norm_title\"] = norm_title_series(akas[\"title\"])\n",
    "aka_join = (\n",
    "    akas.dropna(subset=[\"__norm_title\"])\n",
    "        .merge(\n",
    "            imdb[[\"tconst\", \"__type_grp\", \"startYear\", \"averageRating\", \"numVotes\"]],\n",
    "            left_on=\"titleId\",\n",
    "            right_on=\"tconst\",\n",
    "            how=\"inner\",\n",
    "        )[[\"__norm_title\", \"__type_grp\", \"startYear\", \"averageRating\", \"numVotes\", \"tconst\"]]\n",
    "        .sort_values(\n",
    "            [\"__norm_title\", \"__type_grp\", \"startYear\", \"numVotes\", \"averageRating\"],\n",
    "            ascending=[True, True, True, False, False]\n",
    "        )\n",
    "        .drop_duplicates(subset=[\"__norm_title\", \"__type_grp\", \"startYear\"], keep=\"first\")\n",
    ")\n",
    "\n",
    "need_mask = m2[\"averageRating\"].isna() & m2[\"__norm_title\"].notna()\n",
    "need = m2.loc[need_mask, [\"__norm_title\", \"__type_grp\", \"release_year\"]]\n",
    "\n",
    "j_aka = need.merge(\n",
    "    aka_join,\n",
    "    left_on=[\"__norm_title\", \"__type_grp\", \"release_year\"],\n",
    "    right_on=[\"__norm_title\", \"__type_grp\", \"startYear\"],\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\",\n",
    ")\n",
    "\n",
    "m3 = m2.copy()\n",
    "m3.loc[need_mask, \"averageRating\"] = j_aka[\"averageRating\"].values\n",
    "m3.loc[need_mask, \"numVotes\"]      = j_aka[\"numVotes\"].values\n",
    "m3.loc[need_mask, \"tconst\"]        = j_aka[\"tconst\"].values\n",
    "\n",
    "print(f\"Pass-3 (AKAs, same year): {m3['averageRating'].notna().mean()*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a40dc493-b830-40df-99e9-b7eb07b69939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (19911, 8)\n",
      "\n",
      "Counts by platform:\n",
      "platform\n",
      "Amazon Prime    9659\n",
      "Netflix         8802\n",
      "Disney+         1450\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Counts by type:\n",
      "type\n",
      "Movie      14984\n",
      "TV Show     4927\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top missingness (%):\n",
      "imdb_votes        100.0\n",
      "imdb_rating       100.0\n",
      "content_rating      1.7\n",
      "title               0.0\n",
      "genres              0.0\n",
      "release_year        0.0\n",
      "type                0.0\n",
      "platform            0.0\n",
      "dtype: float64\n",
      "\n",
      "Remaining duplicates by robust key: 0\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat(deduped, ignore_index=True)\n",
    "\n",
    "print(\"Combined shape:\", combined_df.shape)\n",
    "print(\"\\nCounts by platform:\")\n",
    "print(combined_df[\"platform\"].value_counts(dropna=False))\n",
    "\n",
    "if \"type\" in combined_df.columns:\n",
    "    print(\"\\nCounts by type:\")\n",
    "    print(combined_df[\"type\"].value_counts(dropna=False))\n",
    "\n",
    "missing = (combined_df.isna().mean().sort_values(ascending=False) * 100).round(1)\n",
    "print(\"\\nTop missingness (%):\")\n",
    "print(missing.head(12))\n",
    "\n",
    "tmp = combined_df.copy()\n",
    "tmp[\"__norm_title__\"] = _normalize_title_for_dupes(tmp[\"title\"])\n",
    "keys = [k for k in [\"__norm_title__\",\"platform\",\"type\",\"release_year\"] if k in tmp.columns]\n",
    "dups = tmp.duplicated(subset=keys).sum()\n",
    "print(\"\\nRemaining duplicates by robust key:\", dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d00ec6f-39c6-4dc8-9ec5-16ef5a9a63a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset saved: (19911, 14)\n"
     ]
    }
   ],
   "source": [
    "out = m3.rename(columns={\"averageRating\": \"imdb_rating\", \"numVotes\": \"imdb_votes\"})\n",
    "if out.columns.duplicated().any():\n",
    "    out = out.loc[:, ~out.columns.duplicated(keep=\"last\")]\n",
    "    \n",
    "#Make genres readable in CSV\n",
    "if \"genres\" in out.columns:\n",
    "    out[\"genres\"] = out[\"genres\"].apply(lambda xs: \" | \".join(xs) if isinstance(xs, list) else (xs if isinstance(xs, str) else \"\"))\n",
    "\n",
    "# optional: cast IMDb fields (won't error if NaN)\n",
    "for c in (\"imdb_rating\", \"imdb_votes\"):\n",
    "    if c in out.columns:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "\n",
    "cols = [\n",
    "    \"title\", \"type\", \"release_year\", \"genres\", \"platform\", \"content_rating\",\n",
    "    \"imdb_rating\", \"imdb_votes\", \"tconst\"\n",
    "]\n",
    "cols = [c for c in cols if c in out.columns]\n",
    "out[cols].to_csv(\"clean_streaming_metadata.csv\", index=False)\n",
    "\n",
    "print(\"Clean dataset saved:\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf60606-cd82-4b88-aaaa-61c2a315f18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 19911\n",
      "Columns: ['title', 'type', 'release_year', 'genres', 'platform', 'content_rating', 'imdb_rating', 'imdb_votes', 'tconst']\n",
      "\n",
      "Release Year Stats:\n",
      "count    19911.000000\n",
      "mean      2010.554116\n",
      "std         15.949918\n",
      "min       1920.000000\n",
      "25%       2010.000000\n",
      "50%       2016.000000\n",
      "75%       2019.000000\n",
      "max       2021.000000\n",
      "Name: release_year, dtype: float64\n",
      "\n",
      "IMDb Rating Stats:\n",
      "count    13148.000000\n",
      "mean         6.232218\n",
      "std          1.257408\n",
      "min          1.000000\n",
      "25%          5.500000\n",
      "50%          6.400000\n",
      "75%          7.100000\n",
      "max          9.600000\n",
      "Name: imdb_rating, dtype: float64\n",
      "\n",
      "Type distribution:\n",
      "type\n",
      "Movie      75.254884\n",
      "TV Show    24.745116\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values (%):\n",
      "title              0.000000\n",
      "type               0.000000\n",
      "release_year       0.000000\n",
      "genres             0.000000\n",
      "platform           0.000000\n",
      "content_rating     1.727688\n",
      "imdb_rating       33.966149\n",
      "imdb_votes        33.966149\n",
      "tconst            33.966149\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Stats\n",
    "df = pd.read_csv(\"clean_streaming_metadata.csv\")\n",
    "\n",
    "# General overview\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Release year\n",
    "print(\"\\nRelease Year Stats:\")\n",
    "print(df['release_year'].describe())\n",
    "\n",
    "# IMDb rating\n",
    "print(\"\\nIMDb Rating Stats:\")\n",
    "print(df['imdb_rating'].describe())\n",
    "\n",
    "# Content type ratio\n",
    "print(\"\\nType distribution:\")\n",
    "print(df['type'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Missing value percentages\n",
    "print(\"\\nMissing values (%):\")\n",
    "print(df.isnull().mean() * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d692e1-4002-4af8-9238-30f426fae345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
